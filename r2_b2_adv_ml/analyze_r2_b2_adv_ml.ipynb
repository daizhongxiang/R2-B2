{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T13:44:53.890861Z",
     "start_time": "2020-02-12T13:44:53.342522Z"
    }
   },
   "outputs": [],
   "source": [
    "import GPy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T13:44:54.758220Z",
     "start_time": "2020-02-12T13:44:54.711906Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# define below the list of pairs of reasoning levels, in the form of reasoning level of attacker vs defender\n",
    "# use -1 to indicate using R2-B2_Lite and reasoning at level 1\n",
    "reasoning_level_list = [[0, 0],\n",
    "                        [1, 0],\n",
    "                        [-1, 0],\n",
    "                        [0, 1],\n",
    "                        [0, -1],\n",
    "                        [2, 1],\n",
    "                        [1, 2]]\n",
    "\n",
    "all_regret_avg_player_1_mean_list = []\n",
    "all_regret_avg_player_1_stderr_list = []\n",
    "\n",
    "\n",
    "all_successes_list = []\n",
    "\n",
    "# level_zero_policy in {\"random\", \"gp_mw\"}\n",
    "level_zero_policy = \"random\"\n",
    "\n",
    "log_dir = \"results_mnist_\" + level_zero_policy\n",
    "\n",
    "latent_dim = 2\n",
    "\n",
    "sampling_approximation = 500\n",
    "\n",
    "N_iter = 5\n",
    "for r in range(len(reasoning_level_list)):\n",
    "    reasoning_level_1 = reasoning_level_list[r][0]\n",
    "    reasoning_level_2 = reasoning_level_list[r][1]\n",
    "\n",
    "    func_list = np.arange(0, 10)\n",
    "\n",
    "    all_regret_avg_player_1 = []\n",
    "    all_first_success_player_1 = []\n",
    "    successes_list = []\n",
    "    for i in func_list:\n",
    "        if reasoning_level_1 == -1:\n",
    "            log_file_name = log_dir + \"/r2b2_mnist_LD_\" + str(latent_dim) + \"_levels_\" \\\n",
    "                    + str(1) + \"_\" + \\\n",
    "                    str(reasoning_level_2) + \"_approx_samples_\" + str(sampling_approximation) + \\\n",
    "                    \"_iter_\" + str(i) + \"_r2b2_lite.p\"\n",
    "        elif reasoning_level_2 == -1:\n",
    "            log_file_name = log_dir + \"/r2b2_mnist_LD_\" + str(latent_dim) + \"_levels_\" \\\n",
    "                    + str(reasoning_level_1) + \"_\" + \\\n",
    "                    str(1) + \"_approx_samples_\" + str(sampling_approximation) + \\\n",
    "                    \"_iter_\" + str(i) + \"_r2b2_lite.p\"\n",
    "        else:\n",
    "            log_file_name = log_dir + \"/r2b2_mnist_LD_\" + str(latent_dim) + \"_levels_\" \\\n",
    "                    + str(reasoning_level_1) + \"_\" + \\\n",
    "                    str(reasoning_level_2) + \"_approx_samples_\" + str(sampling_approximation) + \\\n",
    "                    \"_iter_\" + str(i) + \".p\"\n",
    "\n",
    "        res = pickle.load(open(log_file_name, \"rb\"))\n",
    "\n",
    "        values_1 = res[\"all\"][\"values_1\"]\n",
    "        init_1 = res[\"all\"][\"init\"][\"Y_1\"]\n",
    "        values_1 = list(init_1) + values_1\n",
    "        values_1_avg = np.cumsum(values_1) / (np.arange(len(values_1)) + 1)\n",
    "        all_regret_avg_player_1.append(values_1_avg)\n",
    "\n",
    "        flags_1 = res[\"all\"][\"F_1\"]\n",
    "        successes_list.append(np.count_nonzero(flags_1))\n",
    "    \n",
    "    all_regret_avg_player_1 = np.array(all_regret_avg_player_1)\n",
    "    all_regret_avg_player_1_mean = np.mean(all_regret_avg_player_1, axis=0)\n",
    "\n",
    "    all_regret_avg_player_1_stderr = np.std(all_regret_avg_player_1, axis=0) / np.sqrt(all_regret_avg_player_1.shape[0])\n",
    "\n",
    "    all_regret_avg_player_1_mean_list.append(all_regret_avg_player_1_mean)\n",
    "    all_regret_avg_player_1_stderr_list.append(all_regret_avg_player_1_stderr)\n",
    "    \n",
    "    all_successes_list.append(successes_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T13:44:56.122610Z",
     "start_time": "2020-02-12T13:44:56.118735Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "all_successes_list = np.array(all_successes_list)\n",
    "print(\"Average # of successful attacks over 150 iterations: \", np.mean(all_successes_list, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T13:44:56.773646Z",
     "start_time": "2020-02-12T13:44:56.768834Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "N_total = len(all_regret_avg_player_1_mean_list)\n",
    "ub_player_1_list = []\n",
    "lb_player_1_list = []\n",
    "for i in range(N_total):\n",
    "    ub_player_1_list.append(all_regret_avg_player_1_mean_list[i] + all_regret_avg_player_1_stderr_list[i])\n",
    "    lb_player_1_list.append(all_regret_avg_player_1_mean_list[i] - all_regret_avg_player_1_stderr_list[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T13:45:02.659547Z",
     "start_time": "2020-02-12T13:45:02.652308Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_mean_and_CI_with_marker(time_steps, mean, lb, ub, color_mean=None, color_shading=None, marker=None, marker_size=12):\n",
    "    plt.fill_between(time_steps, ub, lb,\n",
    "                     color=color_shading, alpha=.2)\n",
    "    plt.plot(time_steps, mean, color_mean, marker=marker, markersize=marker_size, markevery=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T13:45:05.302783Z",
     "start_time": "2020-02-12T13:45:04.985751Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "lw = 2.0\n",
    "plt.rc('font', size=26)\n",
    "plt.figure(figsize=(9.2, 6))\n",
    "\n",
    "color_list = [\"tab:blue\", \"tab:orange\", \"tab:red\", \"tab:green\", \"tab:purple\", \"tab:gray\", \"tab:olive\"]\n",
    "marker_list = [\"v\", \"D\", \"s\", \"o\", \"x\", \"^\", \"<\"]\n",
    "\n",
    "N_total = len(all_regret_avg_player_1_mean_list)\n",
    "inspect_list = np.arange(N_total)\n",
    "for i in inspect_list:\n",
    "    inds = np.arange(len(all_regret_avg_player_1_mean_list[i]))\n",
    "    plot_mean_and_CI_with_marker(inds, all_regret_avg_player_1_mean_list[i], lb_player_1_list[i], ub_player_1_list[i], \\\n",
    "                     color_mean=color_list[i], color_shading=color_list[i], marker=marker_list[i], marker_size=12)\n",
    "\n",
    "# plt.legend((\"Lv 0 vs. Lv 0\", \"Lv 1 vs. Lv 0\", \"Lv 1 vs. Lv 0 (R2-B2-Lite)\", \"Lv 0 vs. Lv 1\", \"Lv 0 vs. Lv 1 (R2-B2-Lite)\", \\\n",
    "#            \"Lv 2 vs. Lv 1\", \"Lv 1 vs. Lv 2\"), \\\n",
    "#           prop={'size':20}, loc='lower left', framealpha=0.7)\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0, len(all_regret_avg_player_1_mean_list[0])])\n",
    "\n",
    "plt.ylabel(\"Attack Score\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T13:45:10.995261Z",
     "start_time": "2020-02-12T13:45:10.966729Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# define below the list of pairs of reasoning levels, in the form of reasoning level of attacker vs defender\n",
    "# use -1 to indicate using R2-B2_Lite and reasoning at level 1\n",
    "reasoning_level_list = [[0, 0],\n",
    "                        [1, 0],\n",
    "                        [-1, 0],\n",
    "                        [0, 1],\n",
    "                        [0, -1],\n",
    "                        [2, 1],\n",
    "                        [1, 2]]\n",
    "\n",
    "all_regret_avg_player_1_mean_list = []\n",
    "all_regret_avg_player_1_stderr_list = []\n",
    "\n",
    "\n",
    "all_successes_list = []\n",
    "\n",
    "# level_zero_policy in {\"random\", \"gp_mw\"}\n",
    "level_zero_policy = \"random\"\n",
    "\n",
    "log_dir = \"results_cifar_\" + level_zero_policy\n",
    "\n",
    "latent_dim = 8\n",
    "\n",
    "sampling_approximation = 1000\n",
    "\n",
    "N_iter = 5\n",
    "for r in range(len(reasoning_level_list)):\n",
    "    reasoning_level_1 = reasoning_level_list[r][0]\n",
    "    reasoning_level_2 = reasoning_level_list[r][1]\n",
    "\n",
    "    func_list = np.arange(0, 10)\n",
    "\n",
    "    all_regret_avg_player_1 = []\n",
    "    all_first_success_player_1 = []\n",
    "    successes_list = []\n",
    "    for i in func_list:\n",
    "        if reasoning_level_1 == -1:\n",
    "            log_file_name = log_dir + \"/r2b2_cifar_LD_\" + str(latent_dim) + \"_levels_\" \\\n",
    "                    + str(1) + \"_\" + \\\n",
    "                    str(reasoning_level_2) + \"_approx_samples_\" + str(sampling_approximation) + \\\n",
    "                    \"_iter_\" + str(i) + \"_r2b2_lite.p\"\n",
    "        elif reasoning_level_2 == -1:\n",
    "            log_file_name = log_dir + \"/r2b2_cifar_LD_\" + str(latent_dim) + \"_levels_\" \\\n",
    "                    + str(reasoning_level_1) + \"_\" + \\\n",
    "                    str(1) + \"_approx_samples_\" + str(sampling_approximation) + \\\n",
    "                    \"_iter_\" + str(i) + \"_r2b2_lite.p\"\n",
    "        else:\n",
    "            log_file_name = log_dir + \"/r2b2_cifar_LD_\" + str(latent_dim) + \"_levels_\" \\\n",
    "                    + str(reasoning_level_1) + \"_\" + \\\n",
    "                    str(reasoning_level_2) + \"_approx_samples_\" + str(sampling_approximation) + \\\n",
    "                    \"_iter_\" + str(i) + \".p\"\n",
    "\n",
    "        res = pickle.load(open(log_file_name, \"rb\"))\n",
    "            \n",
    "        values_1 = res[\"all\"][\"values_1\"]\n",
    "        init_1 = res[\"all\"][\"init\"][\"Y_1\"]\n",
    "        values_1 = list(init_1) + values_1\n",
    "        values_1_avg = np.cumsum(values_1) / (np.arange(len(values_1)) + 1)\n",
    "        all_regret_avg_player_1.append(values_1_avg)\n",
    "\n",
    "        flags_1 = res[\"all\"][\"F_1\"]\n",
    "        successes_list.append(np.count_nonzero(flags_1))\n",
    "    \n",
    "    all_regret_avg_player_1 = np.array(all_regret_avg_player_1)\n",
    "    all_regret_avg_player_1_mean = np.mean(all_regret_avg_player_1, axis=0)\n",
    "\n",
    "    all_regret_avg_player_1_stderr = np.std(all_regret_avg_player_1, axis=0) / np.sqrt(all_regret_avg_player_1.shape[0])\n",
    "\n",
    "    all_regret_avg_player_1_mean_list.append(all_regret_avg_player_1_mean)\n",
    "    all_regret_avg_player_1_stderr_list.append(all_regret_avg_player_1_stderr)\n",
    "    \n",
    "    all_successes_list.append(successes_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T12:05:31.014372Z",
     "start_time": "2020-02-10T12:05:31.007546Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "all_successes_list = np.array(all_successes_list)\n",
    "print(\"Average # of successful attacks over 150 iterations: \", np.mean(all_successes_list, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T12:05:31.487288Z",
     "start_time": "2020-02-10T12:05:31.482862Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "N_total = len(all_regret_avg_player_1_mean_list)\n",
    "ub_player_1_list = []\n",
    "lb_player_1_list = []\n",
    "for i in range(N_total):\n",
    "    ub_player_1_list.append(all_regret_avg_player_1_mean_list[i] + all_regret_avg_player_1_stderr_list[i])\n",
    "    lb_player_1_list.append(all_regret_avg_player_1_mean_list[i] - all_regret_avg_player_1_stderr_list[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T12:05:33.109864Z",
     "start_time": "2020-02-10T12:05:33.104128Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_mean_and_CI_with_marker(time_steps, mean, lb, ub, color_mean=None, color_shading=None, marker=None, marker_size=12):\n",
    "    plt.fill_between(time_steps, ub, lb,\n",
    "                     color=color_shading, alpha=.2)\n",
    "    plt.plot(time_steps, mean, color_mean, marker=marker, markersize=marker_size, markevery=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T12:05:34.422273Z",
     "start_time": "2020-02-10T12:05:34.141909Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "lw = 2.0\n",
    "plt.rc('font', size=26)\n",
    "plt.figure(figsize=(9.2, 6))\n",
    "\n",
    "color_list = [\"tab:blue\", \"tab:orange\", \"tab:red\", \"tab:green\", \"tab:purple\", \"tab:gray\", \"tab:olive\"]\n",
    "marker_list = [\"v\", \"D\", \"s\", \"o\", \"x\", \"^\", \"<\"]\n",
    "\n",
    "N_total = len(all_regret_avg_player_1_mean_list)\n",
    "inspect_list = np.arange(N_total)\n",
    "for i in inspect_list:\n",
    "    inds = np.arange(len(all_regret_avg_player_1_mean_list[i]))\n",
    "    plot_mean_and_CI_with_marker(inds, all_regret_avg_player_1_mean_list[i], lb_player_1_list[i], ub_player_1_list[i], \\\n",
    "                     color_mean=color_list[i], color_shading=color_list[i], marker=marker_list[i], marker_size=12)\n",
    "\n",
    "# plt.legend((\"Lv 0 vs. Lv 0\", \"Lv 1 vs. Lv 0\", \"Lv 1 vs. Lv 0 (R2-B2-Lite)\", \"Lv 0 vs. Lv 1\", \"Lv 0 vs. Lv 1 (R2-B2-Lite)\", \\\n",
    "#            \"Lv 2 vs. Lv 1\", \"Lv 1 vs. Lv 2\"), \\\n",
    "#           prop={'size':20}, loc='lower left', framealpha=0.7)\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0, len(all_regret_avg_player_1_mean_list[0])])\n",
    "\n",
    "plt.ylabel(\"Attack Score\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
