This directory contains the code used in the synthetic experiments (Section 4.1) in the paper "R2-B2: Recursive Reasoning-Based Bayesian Optimization for No-Regret Learning in Games". 
It includes the implementation of the R2-B2 (as well as R2-B2-Lite) algorithm; the implemented level-0 strategies include GP-MW, random search, and EXP3.

Dependencies:
* GPy: https://github.com/SheffieldML/GPy

Description of the scripts:
* bayesian_optimization_r2b2.py: implements the main R2-B2 algorithm
* helper_funcs_r2b2.py: contains some helper functions used by the R2-B2 algorithm (i.e., by bayesian_optimization_r2b2.py)
* run_generate_synth_func.py: generates and saves the synthetic payoff functions (sampled from a Gaussian process) used in all three types of synthetic games
* r2_b2_constant_sum.py: runs the constant-sum synthetic games
* r2_b2_general_sum.py: runs the general-sum synthetic games
* r2_b2_common_payoff.py: runs the common-payoff synthetic games
* analyze_synthetic_games.ipynb: analyzes and visualizes the results
* setup_EXP3.py: generates and saves the random features used by the EXP3 level-0 strategy

Description of the directories:
* results_common_payoff_gp_mw: saves the results for the common-payoff game using the GP-MW level-0 strategy
* results_constant_sum_gp_mw: saves the results for the constant-sum game using the GP-MW level-0 strategy
* results_general_sum_gp_mw: saves the results for the general-sum game using the GP-MW level-0 strategy
Only the "results_general_sum_gp_mw" folder already contains the corresponding results, to avoid excessively large size of the uploaded code.


Description of the files:
* all_funcs_info_new_K_100_ls_0.1.pkl: contains the generated synthetic payoff functions, as well as other auxiliary information; generated by running run_generate_synth_func.py
* sub_domain_K_100.pkl: contains the discrete domain used in the synthetic games; generated by running run_generate_synth_func.py
